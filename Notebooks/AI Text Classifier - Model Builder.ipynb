{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9a89e9",
   "metadata": {},
   "source": [
    "# AI Text Classifier - Model Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eb9b8c",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "The AI Text Classifier is a lightweight tool designed to classify text into predefined categories. It uses machine learning algorithms to learn from labeled datasets and predicts the category for new, unseen text inputs. This project aims to build a functional classifier that can be integrated with AWS Lambda, demonstrating practical experience in AI, Python development, and serverless architecture. The tool is suitable for small-scale, low-latency use cases such as automated email filtering, sentiment monitoring for customer feedback, or simple content moderation tasks.\n",
    "\n",
    "For this project, a Kaggle database containing prelabeled SMS text messages will be used to train the classifier to mark text messages as either spam or ham (not spam). It is important to note that this dataset is highly imbalanced (4825 ham/747 spam --> 86.59% ham/13.41% spam), so additional steps will be needed when building and evaluating the model (Stratified K-Fold Cross Validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cc0785",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c1a7b",
   "metadata": {},
   "source": [
    "### 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f20d65-826a-495d-ad7e-fc7b4f9bd9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -r Resources/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d489a",
   "metadata": {},
   "source": [
    "### 2. Import Required Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a73c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np          # For numerical operations\n",
    "import pandas as pd         # For data import and manipulation\n",
    "import tensorflow as tf     # For deep learning model\n",
    "import pickle               # For saving the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88aea37",
   "metadata": {},
   "source": [
    "#### A. Import Functionality for Building Training and Validation Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c30b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold         # For cross-validation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # For converting text data into numerical data\n",
    "from sklearn import preprocessing                           # For encoding the target variable\n",
    "from sklearn.metrics import accuracy_score                  # For evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f990588",
   "metadata": {},
   "source": [
    "#### B. Import Functionality for Plotting Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e37fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                 # For plotting the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4de315",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e304cc",
   "metadata": {},
   "source": [
    "Text data needs to be converted to numeric representations before it can be used to train deep learning models.\n",
    "\n",
    "The SMS classification feature data is converted to numerical representation using Term Frequencyâ€“Inverse Document Frequency (TF-IDF) encoding. Then, the target variable is converted to one-hot encoding.\n",
    "\n",
    "Perform the following steps for preparing data:\n",
    "\n",
    "1. Load data into a pandas dataframe\n",
    "2. Vectorize and scale the data using TF-IDF encoding\n",
    "3. Convert the dataframe to a numpy array\n",
    "\n",
    "These last two steps are done later in the model training step:\n",
    "\n",
    "4. Use one-hot-encoding for the target variable\n",
    "5. Split into training and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22573f96",
   "metadata": {},
   "source": [
    "### Import Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d98c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SMS spam data into a pandas dataframe and output for review\n",
    "# NOTE: The data is not \"UTF-8\" format. Trying to specify the encoding as \"ISO-8859-1\"\n",
    "spam_data = pd.read_csv(\"Resources/spam.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Separate the feature and target data\n",
    "spam_classifications_raw = spam_data[\"v1\"]\n",
    "spam_messages = spam_data[\"v2\"]\n",
    "\n",
    "print(spam_data.head())\n",
    "print(spam_classifications_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788f92d",
   "metadata": {},
   "source": [
    "### Create Numeric Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Resources.CustomTokenizer import CustomTokenizer\n",
    "\n",
    "# Build a TF-IDF Vectorizer model\n",
    "vectorizer = TfidfVectorizer(tokenizer=CustomTokenizer.customTokenizer)\n",
    "\n",
    "# Transform feature input to numeric values using TF-IDF encoding\n",
    "tfidf = vectorizer.fit_transform(spam_messages)\n",
    "\n",
    "# Convert the TF-IDF encoding to a numpy array\n",
    "tfidf_array = tfidf.toarray()\n",
    "\n",
    "# Build a label encoder for target variable to convert strings to numeric values.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "spam_classifications = label_encoder.fit_transform(spam_classifications_raw)\n",
    "print(spam_classifications)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91da44a7",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d458b3e",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f1e82",
   "metadata": {},
   "source": [
    "Creating a model in Keras requires defining the following:\n",
    "\n",
    "1. Number of hidden layers\n",
    "2. Number of nodes in each layer\n",
    "3. Activation functions\n",
    "4. Loss Function & Accuracy measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Hyper Parameters for building the model\n",
    "NUM_CLASSES = 2                     # Classes in the target variable\n",
    "NUM_NODES = 64                      # Nodes in each hidden layer\n",
    "NUM_HIDDEN_LAYERS = 1               # Number of hidden layers\n",
    "MODEL_TYPE = 'Sequential'           # Type of model\n",
    "HIDDEN_LAYER_ACTIVATION = 'relu'    # Activation function for hidden layers\n",
    "OUTPUT_LAYER_ACTIVATION = 'softmax' # Activation function for output layer\n",
    "\n",
    "# Create a sequential model in Keras\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Activation Functions:\n",
    "# - Relu: Rectified Linear Unit: Returns zero for negative values, else returns the value\n",
    "# - Softmax: Converts the output to a probability distribution\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(tf.keras.layers.Dense(NUM_NODES,                              # Number of nodes\n",
    "                                input_shape=(tfidf_array.shape[1],),    # Number of input variables\n",
    "                                name='Hidden-Layer-1',                  # Logical name\n",
    "                                activation=HIDDEN_LAYER_ACTIVATION))    # Activation function\n",
    "\n",
    "# # Add a second hidden layer\n",
    "# model.add(tf.keras.layers.Dense(NUM_NODES,\n",
    "#                                 name='Hidden-Layer-2',\n",
    "#                                 activation=HIDDEN_LAYER_ACTIVATION))\n",
    "\n",
    "# Add an output layer with softmax activation\n",
    "model.add(tf.keras.layers.Dense(NUM_CLASSES,\n",
    "                                name='Output-Layer',\n",
    "                                activation=OUTPUT_LAYER_ACTIVATION))\n",
    "\n",
    "# Compile the model with loss & metrics\n",
    "# Categorical Crossentropy: Loss function for multi-class classification\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model meta-data\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c21b4f",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8975ae",
   "metadata": {},
   "source": [
    "Training the model involves:\n",
    "\n",
    "1. Define one or more unique training models by setting different hidden layers and hyper parameters\n",
    "2. Perform forward and back propagation\n",
    "3. Evaluate accuracy of each training model\n",
    "4. Repeat to determine best overall training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a8a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it verbose so we can see the progress\n",
    "VERBOSE = 1\n",
    "\n",
    "# Set Up hyper parameters for training\n",
    "BATCH_SIZE = 64         # Number of samples to use in each training cycle\n",
    "EPOCHS = 10             # Number of times to train on the entire dataset\n",
    "NUM_SPLITS = 10         # Number of splits for cross-validation\n",
    "RANDOM_STATE = 24       # Random seed for reproducibility (Ken Griffey Jr's number)\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "# REFERENCE: https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "skf = StratifiedKFold(n_splits=NUM_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Perform Model Training with Stratified K-Fold Cross-Validation\n",
    "model_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(tfidf, spam_classifications):\n",
    "    X_train, X_test = tfidf_array[train_index], tfidf_array[test_index]\n",
    "    Y_train, Y_test = spam_classifications[train_index], spam_classifications[test_index]\n",
    "\n",
    "    # Convert the training and testing target values to one-hot encoding\n",
    "    Y_train = tf.keras.utils.to_categorical(Y_train, 2)\n",
    "    Y_test = tf.keras.utils.to_categorical(Y_test, 2)\n",
    "\n",
    "    # Train the model. This will perform the entire training cycle, including\n",
    "    # forward propagation, loss computation, backward propagation and gradient descent.\n",
    "    # Execute on all data folds and for the specified batch sizes and epochs.\n",
    "    # Perform validation after each epoch.\n",
    "    model.fit(X_train,\n",
    "              Y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              verbose=VERBOSE)\n",
    "\n",
    "    # Make predictions on the test set using the model\n",
    "    Y_predicted = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "    # Convert the expected values for comparison\n",
    "    Y_actual = np.argmax(Y_test, axis=1)\n",
    "\n",
    "    # Calculate the accuracy for this fold\n",
    "    score = accuracy_score(Y_actual, Y_predicted)\n",
    "    model_scores.append(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b99794",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc42297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model accuracy per fold\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(range(1, len(model_scores) + 1), model_scores)\n",
    "\n",
    "# Display the accuracy value on each bar\n",
    "for bar in bars:\n",
    "    x_position = bar.get_x() + bar.get_width() / 2\n",
    "    height = bar.get_height()\n",
    "    y_position = height / 2\n",
    "    label = f'{height:.5f}'\n",
    "    \n",
    "    ax.text(x_position, y_position,\n",
    "            label, ha='center', va='center',\n",
    "            rotation=90, color='white')\n",
    "    \n",
    "# Add labels and title\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training: Model Accuracy per Fold')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Print the average accuracy for all folds\n",
    "average_accuracy = round(sum(model_scores) / len(model_scores), 5)\n",
    "print(f\"Average Accuracy: {average_accuracy:0.5f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba956f5",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c2148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for multiple samples using batch processing\n",
    "\n",
    "testData = [\"FREE entry to a fun contest\",\n",
    "            \"Yup I will come over\",\n",
    "            \"Buy one puppy, get one free\"]\n",
    "\n",
    "# Convert input into IF-IDF vector using the same vectorizer model\n",
    "predict_tfidf=vectorizer.transform(testData).toarray()\n",
    "\n",
    "# Make predictions using the model\n",
    "rawPrediction=model.predict(predict_tfidf)                  # % probability for each class\n",
    "prediction=np.argmax(model.predict(predict_tfidf), axis=1)  # Index of the closest match\n",
    "\n",
    "# Print the final predicted classifications for the test data\n",
    "print(\"\\nPredicted Classes are:\\n\\n\", label_encoder.inverse_transform(prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d499835",
   "metadata": {},
   "source": [
    "## Save the Model and Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c921fd8",
   "metadata": {},
   "source": [
    "All training models and their vectorizers will be automatically saved to the *\"Training Models\"* folder. The final, trained model and its vectorizer will be added to the *\"Resources\"* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "715eaa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training model and vectorizer for future use\n",
    "# Format: basename = type_average_accuracy_epochs_batchSize_hiddenLayers_nodes_activation_output_validation\n",
    "baseName = f'Training Models/{MODEL_TYPE}_{average_accuracy:.5f}_{EPOCHS}'\n",
    "baseName += f'_{BATCH_SIZE}_{NUM_HIDDEN_LAYERS}_{NUM_NODES}'\n",
    "baseName += f'_{HIDDEN_LAYER_ACTIVATION}_{OUTPUT_LAYER_ACTIVATION}'\n",
    "\n",
    "modelName = baseName + '.keras'\n",
    "model.save(modelName)\n",
    "\n",
    "vectorizerName = baseName + '.pkl'\n",
    "with open(vectorizerName, 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda706ab",
   "metadata": {},
   "source": [
    "For validation purposes, reload the saved model and vectorizer and display their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f6b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a Model \n",
    "loaded_model = tf.keras.models.load_model(modelName)\n",
    "\n",
    "# Loading a Vectorizer\n",
    "with open(vectorizerName, 'rb') as file:\n",
    "    loaded_vectorizer = pickle.load(file)\n",
    "\n",
    "# Print Model Summary\n",
    "loaded_model.summary()\n",
    "\n",
    "# Print the loaded vectorizer\n",
    "print(loaded_vectorizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_2015_01_16_rev00",
   "language": "python",
   "name": "venv_2015_01_16_rev00"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
